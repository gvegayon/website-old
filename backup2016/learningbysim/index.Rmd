---
title: "Learning by Simulation"
author: "George G. Vega Yon"
date: "August 4, 2015"
output: 
  html_document:
    css: ../ggvy_style.css
    number_sections: yes
---

# Introduction

This website (intended for personal learning) is designed to be a companion for working with statistics/econometrics and R. In particular, this document has 3 parts: Casella and Berger, Davidson and MacKinnon and Wooldridge.

This is centered on applied methods using R.

The whole idea is that it is easier to learn when you get to 

# Casella and Berger

## Probability Theory
## Transformations and Expectations
## Common Families of Distributions
## Multiple Random Variables
## Properties of Random Sample
## Principles of Data Reduction
## Point Estimation
## Hypothesis Testing

```{r}
library(stats) # Already loaded

# One-way test for equal mean
data(sleep)
head(sleep)

oneway.test(extra~group, sleep)
```

Now, a two sided t-test (default)

```{r}
y <- rnorm(n,mean=2,sd=2)
t.test(x[,1],y, alternative="two.sided")
```

Observe that when we specify one side (suppose greater), the t-stat does not change, only the p-value

```{r}
# Student's t-test
set.seed(123)
n <- 1000
x <- matrix(rnorm(n*2), ncol=2)
t.test(x[,1],x[,2], alternative = 'greater')
```


## Interval Estimation
## Asymptotic Evaluations
## Analysis of Variance and Regression
## Regression Models


# Davison and MacKinnon

## Regression Models

```{r OLS}
# Firs of all, set the seed and the parameters
set.seed(123)
k <- 3
n <- 100

# Generating data (a matrix of 3 variables) and the output y
X <- matrix(rnorm(k*n), ncol=k)
y <- 2 + X[,1]*2 + X[,2]*5 + X[,3]*-1 + rnorm(n)

# Running a simple regression
ols <- lm(y~X)
summary(ols)
```


## The Geometry of Linear Regression
## The Statistical Properties of Ordinary Least Squares
## Hypothesis Testing in Linear Regression Models
## Confidence Intervals
## Generalized Least Squares and Related Topics
## Instrumental Variables Estimation

In this case we will use the package `AER` which provides a out-of-the-box implementation of the Instrumental Variables regression model, remember that we can use the matrix notation for the IV estimator

$$\beta_{IV}=(X'P_WX)^{-1}X'P_Wy$$

Where $P_W$ is the projection matrix that spans the space of our instrument(s) $W$. In order to simulate an instrument, what we will do is create a bivariate normal variable, in order to do that, we will use the function `mvrnorm` from the `MASS` package. The code follows


```{r IV estimation ivreg, message=FALSE}
# Loading the package
library(AER)
library(MASS)

# Firs of all, set the seed and the parameters
set.seed(123)
k <- 3
n <- 100

```

Now we generate the data (assuming that the correlation matrix will be .5 between the instrument and the *unobservable*)

```{r IV estimation ivreg cont, message=FALSE}
# Generating the data
X <- matrix(rnorm((k-1)*n), ncol=k-1)
covar <- matrix(c(1,.5,.5,1),ncol=2,byrow=TRUE)
w <- MASS::mvrnorm(n, mu=c(0,0), Sigma=covar)
```

The output variable will be generated with the `X` matrix and only the first column of the matrix `w`. Observe that the second column will be used as instrument

```{r, message=FALSE}
y <- X[,1]*1 + X[,2]*2 + w[,1*-1] + rnorm(n)

# Running the regression
db <- data.frame(y,X,w)
colnames(db) <- c('y','x1','x2','w1','w2')
iv <- ivreg(y~x1+x2+w1 | x1+x2+w2, data=db)
summary(iv)
```


We can work this out as a two stage OLS

```{r, message=FALSE}
# First stage: Endogenous variable against the instrument
ols1 <- lm(w1~x1+x2+w2, data=db)

# Second stage: Prediction and run the model replacing w1 with w1_hat
db$w1_hat <- predict(ols1)
ols2 <- lm(y~x1+x2+w1_hat,data=db)
ols2
```

Or we can use the formula with the projection matrix

```{r IV estimation lm}
# Using projection matrices
W  <- cbind(1,X,w[,2])
Pw <- W%*%solve(t(W)%*%W)%*%t(W)
Z  <- cbind(1,X,w[,1])
solve(t(Z)%*%Pw%*%Z)%*%t(Z)%*%Pw%*%y
```

Now, to get the variance we will need the `sandwich` package, we will compute the following formula

$$ \sigma^2(X'P_WX)^{-1} $$

```{r, message=FALSE}
# Using the unscaled matrix
unscaled <- summary(ols2)$cov.unscaled
sqrt(diag(unscaled)*summary(ols2)$sigma^2)
```



## The Generalized Method of Moments
## Discrete and Limited Dependent Variables
## Multivariate Models
## Methods for Stationary Time-Series Data
## Unit Roots and Cointegration
## Testing the Especification of Econometric Models


# Wooldridge

## 